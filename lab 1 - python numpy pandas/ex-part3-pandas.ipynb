{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "844c44ad8f7438b79f54d2ec34325b80",
     "grade": false,
     "grade_id": "cell-90cb6b8793cd7b6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 1: Development Basics\n",
    "\n",
    "Version 5.0, Summer Semester 2022\n",
    "\n",
    "## Part 3: Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Name\n",
    "\n",
    "Replace the `raise NotImplementedError` with the code `myname = \"\"` and assign your name to the variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bc4e978fc846dc69988dd013f39fc10",
     "grade": false,
     "grade_id": "name",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b59018434324e604942cea2acc2d2cfe",
     "grade": true,
     "grade_id": "name-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert myname != \"\", \"myname should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccebdba9d551198b5fddca8f45576be6",
     "grade": false,
     "grade_id": "cell-12acfe624fd2f3b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.1: Imports and Data File\n",
    "\n",
    "* Import the numpy library and access it via `np`.\n",
    "* Import pandas with `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "903fe84fbf4e0f4aa4a94ea15303642b",
     "grade": false,
     "grade_id": "import-numpy",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Import numpy (np) and pandas (pd)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply execute this cell for the remaining imports\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use Pandas (`pd`) to load the CSV file we're going to use in this exercise. The Pandas function you need to call is [read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). It requires the URL of the dataset as parameter. Store the created Pandas DataFrame in a variable called `df`.\n",
    "\n",
    "The source URL is: `https://github.com/andijakl/MachineLearning/raw/main/lab%201%20-%20python%20numpy%20pandas/heart_disease_health_indicators_BRFSS2015.csv`\n",
    "\n",
    "The file is around 22 MB, so downloading could take some time.\n",
    "\n",
    "### Dataset info\n",
    "\n",
    "Heart disease is a severe risk and a leading cause of death. Several factors have been identified as risk factors, including high blood pressure, high blood cholesterol and smoking. The Behavioral Risk Factor Surveillance System is a health-related telephone survery conducted annually by the CDC. Each year, they collect responses from over 400,000 Americans.\n",
    "\n",
    "This dataset contains the data from the year 2015. It has been cleaned up from the original responses from 441,455 individuals with 330 features. Incomplete responses have been dropped, and the number of features has been reduced to the ones being considered as having most impact on heart disease risk. It contains 253,680 responses. Note: there is strong class imbalance. 229,787 respondents do not have/have not had heart disease, while 23,893 have had heart disease.\n",
    "\n",
    "We want to answer the question: to what extent can a subset of survey responses from BRFSS be used to predict heart disease risk?\n",
    "\n",
    "* Source: Alex Teboul, CC0 Public Domain: https://www.kaggle.com/alexteboul/heart-disease-health-indicators-dataset/metadata\n",
    "* Cleaned up version of dataset from Centers for Disease Control and Prevention (CDC), CC0 Public Domain: https://www.kaggle.com/cdc/behavioral-risk-factor-surveillance-system\n",
    "* Original dataset at CDC (including older and newer data): https://www.cdc.gov/brfss/annual_data/annual_data.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "808740c39a8f3e1bdc9bea9fc26377d0",
     "grade": false,
     "grade_id": "read-csv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset into variable df\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a37df848c9cb84dfe9af268539c14379",
     "grade": true,
     "grade_id": "read-csv-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df.shape == (253680, 22), \"Imported data should have 253680 rows and 22 columns (including the target column)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb21f1550d334fff76892c1265062cad",
     "grade": false,
     "grade_id": "cell-8f6f73d28c9f5fec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.2: Explore the Dataset\n",
    "\n",
    "Print the first five rows of the dataset using the `head()` function to get a quick glance on what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a52da63f37a9f00496038c637313edda",
     "grade": false,
     "grade_id": "dataset-head",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Use the head() function to print the first 5 rows of the dataset\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `describe()` function of the Pandas DataFrame to find out the count, mean, standard deviation & more from the dataset for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6218597e6937d769e03d3deacc318be6",
     "grade": false,
     "grade_id": "describe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Call method to describe the dataset\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the printed information you see about the dataset, answer a few questions and assign the numbers to the corresponding variables. Round your answers (up/down) to the next integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d2df820f3b441a34fc349ea53360506",
     "grade": false,
     "grade_id": "dataset_data",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# What is the mean BMI?\n",
    "mean_bmi = -1\n",
    "# Are there more smokers than non-smokers in the dataset (1), based on the mean? Or are there more non-smokers than smokers (0)?\n",
    "more_smokers = -1\n",
    "# What is the maximum BMI recorded in the dataset?\n",
    "max_bmi = -1\n",
    "# Remove the exception below after you entered the rounded numbers for the variables\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "399c26201629b14643a97c3769e3d5fb",
     "grade": true,
     "grade_id": "dataset_data_tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert mean_bmi > -1\n",
    "assert more_smokers > -1\n",
    "assert max_bmi > -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3: Plotting\n",
    "\n",
    "Next, plot the histogram of the `BMI` column of the dataframe. Specify that the histogram function should split the data into `30` bins.\n",
    "*Hint:* call the `hist()` function on the column you retrieve from the dataframe. [Read more about it](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html) in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c1063399f73d689c129094dd39f043c",
     "grade": false,
     "grade_id": "histogram",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Call method to print histogram with 10 bins\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4: Counting Values\n",
    "\n",
    "Next, use the `value_counts()` function of the `Stroke` column to see how many persons already had a stroke. Store the results in a new variable called `stroke_count`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d5b434d6b876f7225efdbd56019efc1",
     "grade": false,
     "grade_id": "stroke-count",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define variable stroke_count and store the count of how many persons already had a stroke or not\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb51f0fb6b985a83261699f8c095bdee",
     "grade": true,
     "grade_id": "stroke-count-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert stroke_count.shape == (2,)\n",
    "assert stroke_count[0.0] > 0\n",
    "assert stroke_count[1.0] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more people who did not already have a stroke in the dataset. As such, imagine that some data was missing (e.g., due to a data storage failure or because people didn't want to answer that question). However, you could not afford simply dropping all these people from your dataset. Instead, you'd like to fill the missing values in a way that it stays in line with expectations and shouldn't affect your outcome too much.\n",
    "\n",
    "First, let's say we do not have the stroke answer of the first 100 patients. Use the slice to select the first 100 patients of the `Stroke` column, and again use the `value_counts()` function to see how many people we have in each category for that part. Store the results in a variable `stroke_first_100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68909207ee93f15101a193bef246e9a4",
     "grade": false,
     "grade_id": "stroke-count-100",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define variable stroke_first_100 and assign the value counts of the first 100 rows of the Stroke column\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcbf8a24c5c1657c5993fa4f7acf9ef5",
     "grade": true,
     "grade_id": "stroke-count-100-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert stroke_first_100.shape == (2,)\n",
    "assert stroke_first_100[0.0] > 0\n",
    "assert stroke_first_100[1.0] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Missing Data\n",
    "\n",
    "Now, let's delete the data from our dataset to explore how to fill in missing data as a next step. Assign `np.nan` to the first 100 rows of the `Stroke` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c50955658c2cb116d92ad4094edf0ef",
     "grade": false,
     "grade_id": "stroke-nan",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Assign np.nan to the first 100 items in the Stroke column of the dataframe\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f848de3252d3957988d74e92fcdb737c",
     "grade": true,
     "grade_id": "stroke-nan-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df['Stroke'][0])\n",
    "assert df['Stroke'][0:100].count() == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see how deleting the data is reflected in our `value_counts`. Count the values in the `Stroke` column (this time in the whole column), and assign the result to a variable `stroke_count_nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb5d813e72ab4709338e4973bfd2cb91",
     "grade": false,
     "grade_id": "stroke-nan-count",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Count values in the Stroke column of the dataframe\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a0ac28dc10033c61fedc7d005a99df9",
     "grade": true,
     "grade_id": "stroke-nan-count-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert stroke_count_nan[0.0] == 243297\n",
    "assert stroke_count_nan[1.0] == 10283"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the counts were reduced accordingly. However, `value_counts()` doesn't seem to inform us that we have some missing variables. It simply ignores those. For training a classifier, this is important information, as we need to fix the data beforehand.\n",
    "\n",
    "There is a simple parameter you can add to the `value_counts()` function. Check the [Pandas documentation on value_counts()](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) for the parameter. Run the function again and assign the results to a variable `stroke_count_nan2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbeea1b83bdf2f1cb673bf4137553cc1",
     "grade": false,
     "grade_id": "stroke-nan-count2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Count number of strokes including nan values. Store the results in stroke_count_nan2\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e14d6be6d291c50ba5bb1d7e9d90d74",
     "grade": true,
     "grade_id": "stroke-nan-count2-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert stroke_count_nan2[0.0] == 243297\n",
    "assert stroke_count_nan2[1.0] == 10283\n",
    "assert stroke_count_nan2[np.nan] == 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fba766988d55403ec8fde20e5bfeba8",
     "grade": false,
     "grade_id": "cell-d8e7c3caf325f2ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.6 Fill Missing Data\n",
    "\n",
    "How do we solve the issue with the 100 missing data items about a previous stroke? According to the distribution, the safest bet is to simply set `0` for all missing values. This has by far the greatest chance of being the correct answer.\n",
    "\n",
    "Use the `fillna()` function to set the value 0 for all missing values of the `Stroke` column. As we're now dealing with a very large dataframe, we don't want to create a copy. Instead, the filling function should directly modify the original data. Set the parameter `inplace=True` for the function to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79b4be31aa32cb0e533fdac789ffb309",
     "grade": false,
     "grade_id": "stroke-fillna",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Fill the missing stroke values with 0 and use inplace filling\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55fd4ecc9468cb00afe3e23d7a4c91d2",
     "grade": true,
     "grade_id": "stroke-fillna-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df['Stroke'].value_counts()[0.0] == 243397\n",
    "assert df['Stroke'].value_counts()[1.0] == 10283"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c91951159418843cf7dc8ad7e2fa52ce",
     "grade": false,
     "grade_id": "cell-77031b61265ac3fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.7 Missing Data: Median\n",
    "\n",
    "In other situations, a good strategy could be to replace missing data with the mean or median of the other samples. Let's test this approach with the body mass index (BMI).\n",
    "\n",
    "First, replace the values 500 to 600 of the `BMI` column with `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01db427fc2af41d2fcaeb8753b1a7e01",
     "grade": false,
     "grade_id": "bmi-nan",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Replace values in rows 500 to 600 of column BMI with np.nan\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0521131ea68eaa07557d228e880b82a2",
     "grade": true,
     "grade_id": "bmi-nan-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df['BMI'][500])\n",
    "assert df['BMI'][500:600].count() == 0.0\n",
    "assert df['BMI'].isna().sum() == 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the `median()` function of the dataframe column to calculate the median of the remaining BMI values. Store the result in a new variable called `bmi_median`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f913f74ccec723a2f6fc01ba2f329182",
     "grade": false,
     "grade_id": "bmi-median",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Store the median of the BMI column in a variable called bmi_median\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44fcb9430c593b4cb72c21b82afd15ce",
     "grade": true,
     "grade_id": "bmi-median-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert bmi_median == 27.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, similar to before, replace all missing values in the BMI column with the median from the remaining rows. Again, use the `inplace` variant of the function to directly modify the data we work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c485fade3f1b5ebd33dfcf96570ee53",
     "grade": false,
     "grade_id": "bmi-median-fillna",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Replace the missing BMI values with the median\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4f731eb808a170e082a2999c89d580a",
     "grade": true,
     "grade_id": "bmi-median-fillna-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert not(np.isnan(df['BMI'][500]))\n",
    "assert df['BMI'][500:600].count() > 0.0\n",
    "assert df['BMI'].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c10ac3cc0b96990f9913c301b2f98c65",
     "grade": false,
     "grade_id": "cell-2a25a8138a8b9c25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.8 First Classification: Data Preparation\n",
    "\n",
    "Now that we have the data loaded and prepared, let's quickly do a short test how well a decision tree classifier can predict heart diseases based on the data we have about the patients.\n",
    "\n",
    "First, we need to do a quick additional preparation step: most machine learning libraries need the data and the labels (target classes) in two separate arrays. Simply execute the following line - it will take the `HeartDiseaseorAttack` column (which contains the labels) out of the dataframe and converts it to a numpy array for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply execute this line to extract the target label from the dataframe\n",
    "# Note: you can only execute this line once. If you execute this twice, it will fail\n",
    "# as the column has already been removed from the dataframe. Restart the kernel and run\n",
    "# it again from the top if needed.\n",
    "y = df.pop('HeartDiseaseorAttack').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97a32d97a5c1a9406a41c0611bec0e86",
     "grade": true,
     "grade_id": "df-pop-test",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df.shape == (253680, 21)\n",
    "assert y.shape == (253680,)\n",
    "assert type(y) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step: as you know, it's important to train the classifier only on a part of the available data. The rest should be withheld, to get a more reliable estimate on the quality of the classifier when you test it on previously unseen data.\n",
    "\n",
    "As such, you need to split our large dataset into two parts: training data and test data. As the labels are in a separate array, the same split needs to be applied to the labels, to ensure these are still in the same order and correspond.\n",
    "\n",
    "The `train_test_split()` function of Scikit Learn can do all these tasks in one step. Take a look at the [example from the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Set up the function accordingly.\n",
    "\n",
    "Send both the dataframe and the `y` label array to the function. Use a test size of `0.2`. Also supply a `random_state` of `10`. The function will then return 4 separate arrays. Follow the example in the documentation to see how to provide the four array variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "961146aafa2c3367371535222aa54e8f",
     "grade": false,
     "grade_id": "split",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Split the data and labels into train and test data, using a test size of 0.2 and a random state of 10\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b2b3adbb0ac0adca03089330323e348",
     "grade": true,
     "grade_id": "split_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_train.shape == (202944, 21)\n",
    "assert X_test.shape == (50736, 21)\n",
    "assert y_train.shape == (202944, )\n",
    "assert y_test.shape == (50736, )\n",
    "assert len(X_train['HighBP']) == 202944\n",
    "assert y_test[0] == 1.0\n",
    "assert y_train[100] == 0.0\n",
    "assert X_train['HighBP'][94025] == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e57d345e924587e97d0bedae0b9b0361",
     "grade": false,
     "grade_id": "cell-aed18b4477de32e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.9 Decision Tree Classifier\n",
    "\n",
    "Now, the data is fully prepared. The remaining steps are quite short. We need to create the classifier and fit it on the training data.\n",
    "\n",
    "For this, we will use the [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). Create the object and assign it to a new variable called `clf`. Supply `min_samples_split=30` as parameter to limit the complexity of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bee4ea11a10d2ba4db62a695e7fedf3e",
     "grade": false,
     "grade_id": "create-classifier",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a decision tree classifier with a min sample split of 30. Store it in a variable called clf\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f248288faff2acc86f04d4afd876d6dc",
     "grade": true,
     "grade_id": "create-classifier-test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(clf) == DecisionTreeClassifier\n",
    "assert clf.min_samples_split == 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most complex part of this notebook is actually training the classifier. But for you, that's probably the easiest line. Use the `fit` function of the `clf`. Supply both the training data (`X_train`) as well as the training labels (`y_train`). Depending on your computer speed, this step might take a few seconds. You do not need to assign the result to a variable; the classifier will simply train itself and keep the machine learning model it built for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86ad6763ef0c3501d495177a744cb02a",
     "grade": false,
     "grade_id": "fit-classifier",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let the classifier build its model based on the training data and labels, using the fit() function.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95f32dc02a76e5225756536adc253df8",
     "grade": true,
     "grade_id": "fit-classifier-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert clf.tree_.node_count > 1000\n",
    "assert clf.tree_.children_left.shape[0] > 1000\n",
    "assert clf.tree_.feature[0] > -1\n",
    "assert clf.tree_.threshold[0] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the beginning of the tree. This code is pre-defined, simply execute the following cell to draw the first three layers of the tree, also using the real feature names based on the dataframe columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply execute this block to plot the top of the decision tree\n",
    "plt.figure(figsize=(15,12))  # set plot size (denoted in inches)\n",
    "tree.plot_tree(clf, fontsize=10, max_depth=3, feature_names=df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the data, you will see that for example Age is usually a quite important criteria, with comparison values like `Age <= 9.5`. To understand more about the data, take a look at the dataset description linked above, as well as the [notebook that was used to clean](https://www.kaggle.com/alexteboul/heart-disease-health-indicators-dataset-notebook) the original questionnaire data. You will then see that age starts with `1` (indicating a range of 18-24), then going in 5-year increments until `13` (80 years or older). Think about it: what does the decision if the age is <= 9.5 mean in that case?\n",
    "\n",
    "The last task: let's see how well our classifier performs on previously unseen data. We have split our complete dataset, so we can now use the test data for an independent evaluation.\n",
    "\n",
    "To to this, call the [score()](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier.score) function of the classifier. Supply the test data and the corresponding labels. Store the resulting mean accuracy in a variable called `clf_accuracy` and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d782481fc62e6c956fa255e1c0b4e65",
     "grade": false,
     "grade_id": "score",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the mean accuracy of the classifier model with the test data.\n",
    "# Store the results in a new variable clf_accuracy\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "632cc8e909a65135b2d50364bb800d1b",
     "grade": true,
     "grade_id": "score_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert clf_accuracy > 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To really judge the quality of the results, you'd need to read more about the dataset and calculate additional metrics. But as a first shot using a rather simple decision tree classifier, getting almost 90% accuracy based on questionnaire data is definitely a nice first result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
